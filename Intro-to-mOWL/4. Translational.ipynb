{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "301e5622",
   "metadata": {},
   "source": [
    "# Translational Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1562b1a9",
   "metadata": {},
   "source": [
    "### Knowledge Graph\n",
    "\n",
    "Let $KG = (V, E, L; \\vdash)$ be a knowledge graph with a set of\n",
    "    vertices $V$, a set of edges $E \\subseteq V \\times V$, a label\n",
    "    function $L: V \\cup E \\mapsto Lab$ that assigns labels from a set\n",
    "    of labels $Lab$ to vertices and edges, and an inference relation\n",
    "    $\\vdash$.\n",
    "    \n",
    "**A knowledge graph embedding is a function** $f_\\eta : L(V) \\cup L(E) \\mapsto \\mathbb{R}^n$. That is, the function takes elements from the set $ L(V) \\cup L(E) \\subseteq Lab$ and gets elements in $\\mathbb{R}^n$, where $n$ is the _embedding size_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f375365e",
   "metadata": {},
   "source": [
    "### TransE idea\n",
    "TransE aims to model multirelational data by representing relationships as **translations** in the following way:\n",
    "\n",
    "Consider an edge is the graph of the form $(h, \\ell, t)$, where $h$ is the head of the edge, $\\ell$ is the type of relation and $t$ is the tail of the edge. Let's denote the corresponding embeddings as $\\boldsymbol{h}$, $\\boldsymbol{\\ell}$ and $\\boldsymbol{t}$. TransE learns the embeddings such that: \n",
    "$$\\boldsymbol{h} + \\boldsymbol{\\ell} \\approx \\boldsymbol{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7414d8e",
   "metadata": {},
   "source": [
    "### Objective function\n",
    "TransE minimizes the following objective function: $$\n",
    "\\mathcal{L}=\\sum_{(h, \\ell, t) \\in S} \\sum_{\\left(h^{\\prime}, \\ell, t^{\\prime}\\right) \\in S_{(h, \\ell, t)}^{\\prime}}\\left[\\gamma+d(\\boldsymbol{h}+\\boldsymbol{\\ell}, \\boldsymbol{t})-d\\left(\\boldsymbol{h}^{\\prime}+\\boldsymbol{\\ell}, \\boldsymbol{t}^{\\prime}\\right)\\right]_{+}\n",
    "$$\n",
    "\n",
    "Where $d(\\boldsymbol{h}+\\boldsymbol{\\ell}, \\boldsymbol{t})$ is the _dissimilarity_ score of a positive edge. Furthermore, $d\\left(\\boldsymbol{h}^{\\prime}+\\boldsymbol{\\ell}, \\boldsymbol{t}^{\\prime}\\right)$ is the _dissimilarity_ score for a negative triple obtained by corrupting either the head or tail (but not both) of a positive triple. In this way, TransE favors lower scores for positive edges and big scores for negative edges. \n",
    "\n",
    "Regarding the parameter $\\gamma$, it is used to enforce that the score of a positive edge is different (lower) than the score of a negative edge by at least $\\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0913955a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "import mowl\n",
    "mowl.init_jvm(\"4g\")\n",
    "import torch as th\n",
    "#import logging\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from mowl.visualization.base import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mowl.datasets.ppi_yeast import PPIYeastSlimDataset\n",
    "\n",
    "from mowl.embeddings.translational.model import TranslationalOnt\n",
    "from mowl.projection.factory import projector_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c66a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PPIYeastSlimDataset()\n",
    "projector = projector_factory(\"dl2vec\", bidirectional_taxonomy = True)\n",
    "edges = projector.project(dataset.ontology)\n",
    "modelE = TranslationalOnt(\n",
    "    edges,\n",
    "    trans_method = \"transE\",\n",
    "    embedding_dim = 100,\n",
    "    epochs = 32,\n",
    "    batch_size = 256,\n",
    "    model_filepath = \"/tmp/trans_model.th\"\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfcef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelE.train()\n",
    "modelE.load_best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5afc51c",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = modelE.score_method\n",
    "cls_embs, rel_embs = modelE.get_embeddings()\n",
    "print(rel_embs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mowl.inference.el import GCI2Score\n",
    "\n",
    "scorer = GCI2Score(method, list(cls_embs.keys()), list(rel_embs.keys()))\n",
    "\n",
    "#\"c?.*?4932\\.Q.*? SubClassOf p?.*?            some  c?.*?4932.*?\"\n",
    "#\"c?.*?4932\\.Q.*? SubClassOf p?http://interacts_with? some c?.*?\"\n",
    "preds = scorer.score(\"c?.*?4932\\.Q.*? SubClassOf p?http://interacts_with? some c?.*?4932.*?\")\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mowl.evaluation.predictions import evaluate_predictions\n",
    "from mowl.corpus.base import extract_axiom_corpus\n",
    "corpus = extract_axiom_corpus(dataset.testing)\n",
    "\n",
    "metrics = evaluate_predictions(corpus, preds, [1,10, 100, 1000, 10000, 160000, 162918, 3336802], pos_label = 0)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac756b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "transE_embeddings = modelE.model.entity_representations[0](indices=None).cpu().detach().numpy()\n",
    "protE_embeddings = {}\n",
    "\n",
    "for node, idx in modelE.entities_idx.items():\n",
    "    if node.startswith(\"4932\"):\n",
    "        protE_embeddings[node] = transE_embeddings[idx]\n",
    "        \n",
    "with open(\"data/protE_emb\", \"wb\") as file:\n",
    "    pkl.dump(protE_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347f3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/protE_emb\", \"rb\") as file:\n",
    "    protE_embeddings = pkl.load(file)\n",
    "\n",
    "ec_numbers = {}\n",
    "with open('data/yeast_ec.tab') as f:\n",
    "    next(f)\n",
    "    for line in f:\n",
    "        it = line.strip().split('\\t', -1)\n",
    "        if len(it) < 5:\n",
    "            continue\n",
    "        if it[3]:\n",
    "            prot_id = it[3].split(';')[0]\n",
    "            prot_id = '{0}'.format(prot_id)    \n",
    "            ec_numbers[prot_id] = it[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb07027",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_dict = {}\n",
    "for prot in ec_numbers:\n",
    "    if prot in protE_embeddings:\n",
    "        ec_dict[prot] = protE_embeddings[prot]\n",
    "        \n",
    "size = modelE.embedding_dim\n",
    "embeds = np.zeros((len(ec_dict), size), dtype=np.float32)\n",
    "\n",
    "for i, emb in enumerate(ec_dict.values()):\n",
    "    embeds[i, :] = emb\n",
    "nodemap = {}\n",
    "for i, m in enumerate(ec_dict.keys()):\n",
    "    nodemap[i] = m\n",
    "    \n",
    "\n",
    "X = TSNE(n_components=2, verbose=1, n_iter=5000, n_jobs=8).fit_transform(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'0': [[], []]}\n",
    "for item in nodemap.items():\n",
    "    k, v = item\n",
    "    if v in ec_numbers:\n",
    "        ec = ec_numbers[v].split('.')[0]\n",
    "        if ec not in classes:\n",
    "            classes[ec] = [[], []]\n",
    "        classes[ec][0].append(X[k, 0])\n",
    "        classes[ec][1].append(X[k, 1])\n",
    "        \n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, len(classes))))\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "for ec, items in classes.items():\n",
    "    if ec == '0':\n",
    "        continue\n",
    "    color = next(colors)\n",
    "    ax.scatter(items[0], items[1], color=color, label=ec)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.savefig('data/fig_transE.jpg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f177f03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e32f20d2",
   "metadata": {},
   "source": [
    "## TransH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PPIYeastSlimDataset()\n",
    "    \n",
    "modelH = TranslationalOnt(\n",
    "        dataset, \n",
    "        parsing_method = \"dl2vec\", \n",
    "        trans_method = \"transH\",\n",
    "        embedding_dim = 100,\n",
    "        epochs = 32,\n",
    "        batch_size = 256,\n",
    "        bidirectional_taxonomy = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1cbd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelH.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957278cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "transH_embeddings = modelH.model.entity_representations[0](indices=None).cpu().detach().numpy()\n",
    "protH_embeddings = {}\n",
    "\n",
    "for node, idx in modelH.entities_idx.items():\n",
    "    if node.startswith(\"4932\"):\n",
    "        protH_embeddings[node] = transH_embeddings[idx]\n",
    "        \n",
    "with open(\"data/protH_emb\", \"wb\") as file:\n",
    "    pkl.dump(protH_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab251627",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_dict_H = {}\n",
    "for prot in ec_numbers:\n",
    "    if prot in protH_embeddings:\n",
    "        ec_dict_H[prot] = protH_embeddings[prot]\n",
    "        \n",
    "size = modelH.embedding_dim\n",
    "embedsH = np.zeros((len(ec_dict_H), size), dtype=np.float32)\n",
    "\n",
    "for i, emb in enumerate(ec_dict_H.values()):\n",
    "    embedsH[i, :] = emb\n",
    "nodemapH = {}\n",
    "for i, m in enumerate(ec_dict_H.keys()):\n",
    "    nodemapH[i] = m\n",
    "    \n",
    "\n",
    "XH = TSNE(n_components=2, verbose=1, n_iter=5000, n_jobs=8).fit_transform(embedsH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d01e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'0': [[], []]}\n",
    "for item in nodemapH.items():\n",
    "    k, v = item\n",
    "    if v in ec_numbers:\n",
    "        ec = ec_numbers[v].split('.')[0]\n",
    "        if ec not in classes:\n",
    "            classes[ec] = [[], []]\n",
    "        classes[ec][0].append(XH[k, 0])\n",
    "        classes[ec][1].append(XH[k, 1])\n",
    "        \n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, len(classes))))\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "for ec, items in classes.items():\n",
    "    if ec == '0':\n",
    "        continue\n",
    "    color = next(colors)\n",
    "    ax.scatter(items[0], items[1], color=color, label=ec)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.savefig('data/fig_transH.jpg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839f5c2",
   "metadata": {},
   "source": [
    "## TransR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PPIYeastSlimDataset()\n",
    "    \n",
    "modelR = TranslationalOnt(\n",
    "        dataset, \n",
    "        parsing_method = \"dl2vec\", \n",
    "        trans_method = \"transR\",\n",
    "        embedding_dim = 100,\n",
    "        epochs = 32,\n",
    "        batch_size = 256,\n",
    "        bidirectional_taxonomy = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b1572",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelR.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46b0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transR_embeddings = modelR.model.entity_representations[0](indices=None).cpu().detach().numpy()\n",
    "protR_embeddings = {}\n",
    "\n",
    "for node, idx in modelR.entities_idx.items():\n",
    "    if node.startswith(\"4932\"):\n",
    "        protR_embeddings[node] = transR_embeddings[idx]\n",
    "        \n",
    "with open(\"data/protR_emb\", \"wb\") as file:\n",
    "    pkl.dump(protR_embeddings, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed4cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_dict_R = {}\n",
    "for prot in ec_numbers:\n",
    "    if prot in protR_embeddings:\n",
    "        ec_dict_R[prot] = protR_embeddings[prot]\n",
    "        \n",
    "size = modelR.embedding_dim\n",
    "embedsR = np.zeros((len(ec_dict_R), size), dtype=np.float32)\n",
    "\n",
    "for i, emb in enumerate(ec_dict_R.values()):\n",
    "    embedsR[i, :] = emb\n",
    "nodemapR = {}\n",
    "for i, m in enumerate(ec_dict_R.keys()):\n",
    "    nodemapR[i] = m\n",
    "    \n",
    "\n",
    "XR = TSNE(n_components=2, verbose=1, n_iter=5000, n_jobs=8).fit_transform(embedsR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4377fe57",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {'0': [[], []]}\n",
    "for item in nodemapR.items():\n",
    "    k, v = item\n",
    "    if v in ec_numbers:\n",
    "        ec = ec_numbers[v].split('.')[0]\n",
    "        if ec not in classes:\n",
    "            classes[ec] = [[], []]\n",
    "        classes[ec][0].append(XR[k, 0])\n",
    "        classes[ec][1].append(XR[k, 1])\n",
    "        \n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, len(classes))))\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "for ec, items in classes.items():\n",
    "    if ec == '0':\n",
    "        continue\n",
    "    color = next(colors)\n",
    "    ax.scatter(items[0], items[1], color=color, label=ec)\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.savefig('data/fig_transR.jpg')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b91e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsR = modelR.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ded6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsR.hits_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1dc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mowldev",
   "language": "python",
   "name": "mowldev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
